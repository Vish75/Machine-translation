{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "id": "du0x83uGOnue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De4HhMGkNHQw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "train_data = load_dataset(\"wmt16\",\"de-en\", split=\"train[:50000]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers nltk bert-score matplotlib tqdm\n"
      ],
      "metadata": {
        "id": "is76KmrxUh59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from transformers import EncoderDecoderModel, EncoderDecoderConfig, BertTokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from bert_score import score as bert_score\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Define dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer_de, tokenizer_en):\n",
        "        self.data = data\n",
        "        self.tokenizer_de = tokenizer_de\n",
        "        self.tokenizer_en = tokenizer_en\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        translation = self.data[idx]['translation']  # Access the 'translation' key\n",
        "        src_text = translation['de']  # Access the 'de' key within 'translation'\n",
        "        tgt_text = translation['en']  # Access the 'en' key within 'translation'\n",
        "        src_tokens = self.tokenizer_de(src_text, padding=True, truncation=True, return_tensors='pt')['input_ids']\n",
        "        tgt_tokens = self.tokenizer_en(tgt_text, padding=True, truncation=True, return_tensors='pt')['input_ids']\n",
        "        return {'src_tokens': src_tokens.squeeze(), 'tgt_tokens': tgt_tokens.squeeze()}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Sort batch by sequence length for efficient padding\n",
        "        batch = sorted(batch, key=lambda x: x['src_tokens'].shape[0], reverse=True)\n",
        "\n",
        "        # Pad sequences to the length of the longest sequence in the batch\n",
        "        src_tokens = pad_sequence([x['src_tokens'] for x in batch], batch_first=True, padding_value=tokenizer_de.pad_token_id)\n",
        "        tgt_tokens = pad_sequence([x['tgt_tokens'] for x in batch], batch_first=True, padding_value=tokenizer_en.pad_token_id)\n",
        "\n",
        "        return {'src_tokens': src_tokens, 'tgt_tokens': tgt_tokens}\n",
        "\n",
        "# Define model configuration\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
        "    EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-german-cased', 'bert-base-uncased').config.encoder,\n",
        "    EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-german-cased', 'bert-base-uncased').config.decoder\n",
        ")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer_de = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
        "tokenizer_en = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define model\n",
        "model = EncoderDecoderModel(config)\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Load data\n",
        "train_data = load_dataset(\"wmt16\",\"de-en\", split=\"train[:50000]\")  # Load training data\n",
        "valid_data = load_dataset(\"wmt16\",\"de-en\", split=\"validation\")  # Load validation data\n",
        "test_data = load_dataset(\"wmt16\",\"de-en\", split=\"test\")  # Load test data\n",
        "\n",
        "# Initialize datasets and dataloaders\n",
        "train_dataset = TranslationDataset(train_data, tokenizer_de, tokenizer_en)\n",
        "valid_dataset = TranslationDataset(valid_data, tokenizer_de, tokenizer_en)\n",
        "test_dataset = TranslationDataset(test_data, tokenizer_de, tokenizer_en)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Implement gradient accumulation\n",
        "accumulation_steps = 4  # Accumulate gradients over 4 steps\n",
        "\n",
        "# Training loop\n",
        "'''def train_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        src_tokens = batch['src_tokens'].to(device)\n",
        "        tgt_tokens = batch['tgt_tokens'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=src_tokens, decoder_input_ids=tgt_tokens[:, :-1], labels=tgt_tokens[:, 1:])\n",
        "        loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), tgt_tokens[:, 1:].view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)'''\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, accumulation_steps, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Training\")):  # Add batch_idx here\n",
        "        src_tokens = batch['src_tokens'].to(device)\n",
        "        tgt_tokens = batch['tgt_tokens'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=src_tokens, decoder_input_ids=tgt_tokens[:, :-1], labels=tgt_tokens[:, 1:].contiguous())\n",
        "        logits_shape = outputs.logits.shape\n",
        "        labels_shape = tgt_tokens[:, 1:].shape\n",
        "        print(\"Logits shape:\", logits_shape)\n",
        "        print(\"Labels shape:\", labels_shape)\n",
        "        loss = criterion(outputs.logits.reshape(-1, outputs.logits.size(-1)), tgt_tokens[:, 1:].reshape(-1))\n",
        "        loss = loss / accumulation_steps  # Normalize the loss\n",
        "        loss.backward()  # Backpropagate the gradients\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:  # Only update the weights every `accumulation_steps` batches\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "# Move model to the same device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            src_tokens = batch['src_tokens'].to(device)\n",
        "            tgt_tokens = batch['tgt_tokens'].to(device)\n",
        "\n",
        "            # Generate predictions\n",
        "            generated = model.generate(src_tokens, decoder_start_token_id=tokenizer_en.cls_token_id)\n",
        "            predictions.extend(generated)\n",
        "            targets.extend(tgt_tokens[:, 1:].cpu().numpy())\n",
        "    predictions = [tokenizer_en.decode(ids, skip_special_tokens=True) for ids in predictions]\n",
        "    targets = [tokenizer_en.decode(ids, skip_special_tokens=True) for ids in targets]\n",
        "    return predictions, targets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, accumulation_steps,device)\n",
        "    valid_loss = evaluate(model, valid_loader,device)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "# Save model checkpoint\n",
        "torch.save(model.state_dict(), 'model_checkpoint.pth')\n",
        "\n",
        "# Evaluation\n",
        "test_predictions, test_targets = evaluate(model, test_loader, device)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "bleu_score = corpus_bleu([[tgt.split()] for tgt in test_targets], [pred.split() for pred in test_predictions])\n",
        "meteor_score_avg = meteor_score(test_targets, test_predictions)\n",
        "bert_score_p, bert_score_r, bert_score_f1 = bert_score(test_predictions, test_targets, lang='en', model_type='bert-base-uncased', nthreads=4)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"BLEU Score:\", bleu_score)\n",
        "print(\"METEOR Score:\", meteor_score_avg)\n",
        "print(\"BERTScore Precision:\", bert_score_p.mean())\n",
        "print(\"BERTScore Recall:\", bert_score_r.mean())\n",
        "print(\"BERTScore F1:\", bert_score_f1.mean())\n"
      ],
      "metadata": {
        "id": "nHvMyHA-QIjC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}